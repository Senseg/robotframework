Configuring execution
----------------------

This section explains different command line options that can be used
configuring the `test execution`_ or `post-processing outputs`_
somehow. Options related to generated output files are discussedin in
the `next section`__.

__ `Output files`_

.. contents::
   :depth: 2
   :local:


Selecting test cases
~~~~~~~~~~~~~~~~~~~~

Robot Framework offers several command line options for selecting
which test cases to execute. Same options also work when
post-processing outputs with :prog:`rebot` tool.


By test suite and test case names
'''''''''''''''''''''''''''''''''

Test suites and test cases can be selected by their names with command
line options :setting:`--suite (-s)` and :setting:`--test (-t)`,
respectively.  Both of these options can be used multiple times to
select multiple test suites or cases. Arguments to these options are
case and space insensitive, and theys can be also be `simple
patterns`_ matching multiple names.  If both :setting:`--suite` and
:setting:`--test` options are used, only test cases in matching suites
with matching names are selected.

::

  --test Example
  --test mytest --test yourtest
  --test example*
  --suite example-??
  --suite mysuite --test mytest --test your*

Using :setting:`--suite` option is more or less same as executing only
the appropriate test case file or directory. One major benefit is the
possibility to select the suite based on its parent suite. The syntax
for this is specifying both the parent and child suite names separated
with a dot.  In this case possible setup and teardown of the parent
suite are executed.

::

  --suite parent.child
  --suite myhouse.myhousemusic --test jack*

Selecting individual test cases with :setting:`--test` option is very
handy when creating test cases, but quite limited when running tests
automatically. :setting:`--suite` option can be useful also in that
case, but in general selecting test cases by tag names is more
flexible.

By tag names
''''''''''''

It is possible to include and exclude test cases by tag_ names with
:setting:`--include (-i)` and :setting:`--exclude (-e)` options,
respectively. When the former is used, only test cases having a
matching tag are selected, and with the latter test cases having a
matching tag are not. If both are used, only tests having a tag
matching the former option, and not having a tag matching the latter
are selected.

::

   --include example
   --exclude not_ready
   --include regression --exclude long_lasting

Both :setting:`--include` and :setting:`--exclude` can be used several
times to match multiple tags, and their arguments can be `simple
patterns`_. In these cases the rules for selecting test cases apply so
that test cases having any tag matching any include patterns are
selected, and tests having any tag matching exclude patterns are not.
It is also possible to select only test cases that have two or more
specified tags by separating tags either with :code:`&` or :code:`AND`
(case-sensitive). Similarly only tests with a certain tag but without
another can be selected by separating these tags with :code:`NOT`
(case-sensitive).

::

  --include req-*
  --include regressionANDiter-42
  --include tag1&tag2&tag3&tag4
  --exclude regressionNOTowner-*

Selecting test cases by tags is a really flexible machanism and allows
many interesting possibilities:

- A subset of tests to be executed before other tests can be tagged
  with :setting:`smoke` and executed with :cli:`--include smoke`.

- Unfinished test can be committed to version control with a tag
  :setting:`not_ready` and excluded from the test execution with
  :cli:`--exclude not_ready`.

- Tests can be tagged with :setting:`iter-<num>`, where
  :setting:`<num>` specifies the number of the current iteration, and
  after executing all test cases a separate report containing only
  tests for certain iteration can be generated like :cli:`rebot
  --include iter-42 ouput.xml`.


Setting criticality
~~~~~~~~~~~~~~~~~~~

TODO: Peke continues here on Monday

The final result of test execution is determined on the basis of
critical tests. If a single critical test fails, the whole test run is
considered failed, but non-critical test cases can fail without the
overall status changing. 

By default all test cases are critical, but this can be changed with
:setting:`--critical (-c)` and :setting:`--noncritical (-n)`
options. These options specify which test cases are consider critical
based on tags similarly as :setting:`--include` and
:setting:`--exclude` are used to `select test cases by tag
names`__. In short this means that test cases having a critical tag
are considered critical unless they also have a non-critical tag, and
that these options accept `simple patterns`_ and can be given multiple times.

__ `By tag names`_

::

  --critical regression
  --noncritical not_ready
  --critical iter-* --critical req-* --noncritical req-6??

The most common use case for setting criticality is having test cases
that are not ready or that are testing features still under
development in the test execution. These tests could, of course, be
excluded from the test execution altogether with :setting:`--exclude`
option, but including them as non-critical tests makes it possible to
see when they start to pass.

.. Note:: Currently criticality set when tests are executed is not
          changed when `post-processing outputs`_ unless
          :setting:`--critical` or :setting:`--noncritical` is used
          explicitly. In the future this will change so that they need
          to be used always.


Setting metadata
~~~~~~~~~~~~~~~~

Setting name
''''''''''''

When Robot Framework parses test data, a name for the top-level suite
is based on the data source path. This can be overridden with the
command line option :setting:`--name (-N)`. The argument is
capitalized and underscores are converted to spaces.

Setting documentation
'''''''''''''''''''''

In addition to defining documentation in the test data, documentation
for the top-level suite may also be given from the command line with the
option :setting:`--doc (-D)`. The given documenatation may contain simple
HTML formatting.

Setting free metadata
'''''''''''''''''''''

`Free test suite metadata`_ may also be given from the command line with the option
:setting:`--metadata (-M)`. The argument must be in the format :setting:`name:value`, where
"name" is capitalized and undescores converted to spaces and "value" may 
contain simple HTML formatting. This option may be used several times.

Setting tags
''''''''''''

The command line option :setting:`--settag (-G)` can be used to set the given tag to 
all executed test cases. This option may be used several times.

Adjusting the library search path
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When test libraries are introduced in the test data, Robot Framework
attempts to find the library code from locations defined in the
PYTHONPATH environment variable. When tests are executed with Jython,
also the CLASSPATH environment variable is used to determine the
search path. The command line option :setting:`--pythonpath` can be
used to add directories to the PYTHONPATH environment variable.

It is usually best to create a start-up script for setting the environment
variables.

Setting variables
~~~~~~~~~~~~~~~~~

You can also define a variable_ from the command line, either
directly or from a variable file. These variables override any 
variables with same name in test case and resource files. 

The option :setting:`--variable (-v)` takes an argument in the format
:setting:`name:value`, where "name" must be given without "${}". This
option can only be used to create scalar variables. Examples::

  --variable str:Hello  =>  ${str} = 'Hello'
  -v str:Hi_World -E space:_  =>  ${str} = 'Hi World'
  -v x: -v y:42  =>  ${x} = '', ${y} = '42'

The option :setting:`--variablefile (-V)` can be used to take a `variable file`__
into use. Argument for this option is either relative or absolute path to the file.

__ `Variable files`

Setting runmode
~~~~~~~~~~~~~~~

There is a command line option :setting:`--runmode`, which can be used to define
some additional characteristics of the test execution. Currently it has four
meaningful values, all other values are just ignored. The possible values are:

:setting:`random:test`
    Tests inside each suite are executed in random order.

:setting:`random:suite`
    All suites are executed in random order.

:setting:`random:all`
    Suites are executed in random order, tests inside suites likewise.

:setting:`exitonfailure`
    Test execution is stopped whenever a critical test fails. All remaining
    test will be marked failed with the message 
    :msg:`Critical failure occurred and ExitOnFailure option is in use`.


Controlling monitor output
~~~~~~~~~~~~~~~~~~~~~~~~~~

The width of the console output can be defined using the option :setting:`-- monitorwidth`.
The default value for the monitor width is 78.

:setting:`--monitorcolors` is used to control whether colors should be used
in the monitor output. It has three possible values, of which :setting:`on` is the
default value:

:setting:`on`
    Colors are used in UNIX-like systems, but not on Windows.

:setting:`off`
    Colors are never used.

:setting:`force`
    Colors are always used.


Setting listeners
~~~~~~~~~~~~~~~~~

The only way to use a listener__ during execution is to define it from
the command line using the option :setting:`--listener`. The listener
class must be found in PYTHONPATH__.

__ `Using the listener interface`_
__ `Adjusting the library search path`_


Setting times for combined outputs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When combining outputs with rebot, it possible to set the start and end
time of the combined suite using the option :setting:`--starttime` and 
:setting:`--endtime`. This may be convenient, because by default,
these statistics have no value in the combined suite.




